<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>How [not] to evaluate your RAG</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/dracula.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>HOW <s>NOT</s> TO EVALUATE</h2>
				<img src="img/main.png" height="350px" style="margin: 0px;">
				<h1>your RAG</h1>

				<small>Berlin Buzzwords 2025 | Roman Grebennikov</small>
			</section>
			<section>
				<h2>whoami</h2>
				<p><img src="img/ava.jpg" height="200px"></p>
				<ul>
					<li>PhD in CS, quant trading, credit scoring</li>
					<li><strong>Findify</strong>: e-commerce search, personalization</li>
					<li><strong>Delivery Hero</strong>: food search, LLMs</li>
					<li><strong>Opensource</strong>: Metarank, lightgbm4j, flink-scala-api</li>
				</ul>
			</section>
			<section>
				<h2>Nixiesearch</h2>
				<img src="img/arch.png" height="200px">
				<ul>
					<li><strong>TLDR:</strong> Lucene search engine on top of S3</li>
					<li><strong>Expected:</strong> facets, filters, autocomplete, RFF</li>
					<li><strong>ML:</strong> embedding inference, cross-encoder ranking</li>
					<li><strong>RAG:</strong> LLM inference via llamacpp</li>
				</ul>
			</section>
			<section>
				<h2>Perks of being open-source</h2>
				<br />
				<ul>
					<li class="fragment"><strong>they</strong>: hey nice project!</li>
					<li class="fragment"><strong>you</strong>: thanks! ‚ù§Ô∏è</li>
					<li class="fragment"><strong>they</strong>: we use it for RAG in a bank with 3M customers</li>
					<li class="fragment"><strong>they</strong>: and got some issues, can you help?</li>
					<li class="fragment"><strong>you</strong>: hmm ü§îü§îü§î</li>
				</ul>
			</section>
			<section>
				<h2>The agenda</h2>
				<img src="img/bitch.png" height="300px">
				<ul>
					<li><strong>intro</strong>: RAG as a support agent for support agents</li>
					<li><strong>data</strong>: chunking and context length</li>
					<li><strong>search+generation</strong>: the R and G in RAG</li>
					<li>
						<strong>tools</strong>: RAGAS, deepeval and why you should build your own
					</li>
				</ul>
			</section>
			<section>
				<h2>Support agent for support agents</h2>
				<p>80% of all questions are covered by FAQ</p>
				<img src="img/balance.png" height="200px">
				<ul>
					<li><strong>40%</strong>: answer immediately as you know the answer</li>
					<li><strong>40%</strong>: answer after checking FAQ/docs</li>
					<li><strong>20%</strong>: answer after internal discussion</li>
				</ul>
			</section>
			<section>
				<h2>Support agent for support agents</h2>
				<img src="img/bot-idea.png" height="400px">
				<ul>
					<li><strong>Still human</strong>: nobody likes chatting with ChatGPT</li>
					<li><strong>Faster onboarding</strong>: just read the docs</li>
				</ul>
			</section>
			<section>
				<h2>RAG</h2>
				<ul>
					<li>Dialogue: summarize to a query</li>
					<li>Retrieve: search for top-N relevant docs</li>
					<li>Summarize: answer the last question in the dialogue</li>
				</ul>
				<img src="img/bot-idea.png" height="400px">
			</section>
			<section>
				<h2>Getting real</h2>
				<img src="img/uzbek.png" height="350px">
				<ul>
					<li><strong>FinTech</strong>: airgapped, you can't just use OpenAI API</li>
					<li><strong>Languages</strong>: CIS region, Uzbek/Kazakh</li>
					<li><strong>Knowledge base</strong>: what knowledge base?</li>
				</ul>
			</section>
			<section>
				<h2>wait is RAG solved thing in 2025?</h2>
				<img src="img/rags.png" height="400px">
			</section>
			<section>
				<h2>Iteration #1</h2>
				<ul>
					<li>LLM convert all docs to Markdown</li>
					<li>LangChain chunk, embed with multilingual-e5-small</li>
					<li>Qwen2.5 for summarization</li>
				</ul>
				<img src="img/ctok.png" height="400px">
			</section>
			<section>
				<h2>CTO@k: it works but sucks</h2>
				<ul>
					<li>Relevant docs missing, irrelevant found</li>
					<li>Wrong query (or summary) generated</li>
				</ul>
			</section>
			<section>
				<h2>CTO@k: it works but sucks</h2>
				<ul>
					<li><strong>R: </strong>Relevant docs missing, irrelevant found</li>
					<li><strong>G: </strong>Wrong query (or summary) generated</li>
				</ul>
			</section>
			<section>
				<h2>RAG in a nutshell</h2>
				<img src="img/rag-nut.png" height="400px">
			</section>
			<section>
				<h2>Vibe-evaluating RAG</h2>
				<img src="img/ragas.png" height="400px">
				<p>TLDR: evaluate each RAG step separately</p>
			</section>
			<section>
				<h2>RAG as a system</h2>
				<p>preprocessing + retrieval + generation = RAG</p>
				<img src="img/men.png" height="500px" style="margin: 0px;">
			</section>
			<section>
				<h2>decompose > evaluate > improve</h2>
			</section>
			<section>
				<h2>Corpus preprocessing</h2>
				<img src="img/incredible.png" height="500px">
			</section>
			<section>
				<h2>Corpus preprocessing</h2>
				<img src="img/incredible.png" height="300px">
				<ul>
					<li>Local files: docx, pdf, txt, napkin scans</li>
					<li>Convert everything to markdown</li>
				</ul>
			</section>
			<section>
				<h2>Evaluating chunking</h2>
				<p><img src="img/use_your_product.jpg" height="300px"></p>
				<ul>
					<li>chunking = the way you create corpus</li>
					<li>cannot label changing corpus üôÅ</li>
				</ul>
				<p>"vibe fixing"</p>
			</section>
			<section>
				<h2>Chunking: large vs small</h2>
				<ul>
					<li><strong>Large</strong>: embed complete documents</li>
					<li><strong>Small</strong>: split docs to chunks</li>
				</ul>
			</section>
			<section>
				<h2>Problems of large chunking</h2>
				<img src="img/books.png" height="450px">
				<p>Bad UX: no time to check, context too large</p>
			</section>
			<section>
				<h2>Problems of small chunking</h2>
				<img src="img/chunks.png" height="300px">
				<p>Lost context due to over-chunking</p>
			</section>
			<section>
				<h2>Anthropic's contextual chunking</h2>
				<img src="img/context.png">
			</section>
			<section>
				<h2>Anthropic's contextual chunking</h2>
				<img src="img/context.png" height="300px">
				<ul>
					<li>LLM inference per chunk is expensive üôÅ</li>
					<li>Yes but we have markdown titles üòÉ</li>
				</ul>
			</section>
			<section>
				<h2>GPU poor contextual chunking</h2>
				<img src="img/context-chunks.png" height="500px">
			</section>
			<section>
				<h2>Chunking TLDR</h2>
				<img src="img/win.png" height="450px">
				<ul>
					<li>Contextual: title + 1-2 paragraphs</li>
				</ul>
			</section>
			<section>
				<h2>R in RAG</h2>
				<img src="img/ragas-metrics.png" height="450px">
			</section>
			<section>
				<h2>R in RAG</h2>
				<img src="img/search-metrics.png" height="500px">
			</section>
			<section>
				<h2>The most relevant context</h2>
				<img src="img/rag-nut.png" height="300px">
				<ul>
					<li>Context window is limited (but it's growing)</li>
					<li>Fill the context with relevant chunks</li>
				</ul>
			</section>
			<section>
				<h2>Which model to choose?</h2>
				<p>Not all embeddings are OK for non-English!</p>
				<ul>
					<li>No labels, no queries, unusual languages</li>
					<li>No baseline to compare against</li>
					<li>No public eval corpus üôÅ</li>
				</ul>
			</section>
			<section>
				<h2>MIRACL dataset</h2>
				<img src="img/miracl.png" height="400px">
				<ul>
					<li>TLDR: wikipedia query + docs + labels, 18 languages</li>
					<li>No Kazakh/Uzbek split, but what if we machine-translate? ü§î</li>
				</ul>
			</section>
			<section>
				<h2>Machine-translated datasets?</h2>
				<p>m-MARCO: A Multilingual Version of the MS MARCO [2021]</p>
				<img src="img/mmarco.png" height="350px">
				<p>Are MT/LLM models of 2025 better? ü§î</p>
			</section>
			<section>
				<h2>XCOMET, en->xx</h2>
				<img src="img/xcomet.png" height="400px">
				<ul>
					<li>Google Translate: great on high-resource languages</li>
					<li>GPT4o: strong on low-resource languages</li>
				</ul>
			</section>
			<section>
				<h2>MTEB eval on MT data</h2>
				<img src="img/embeds.png">
				<ul>
					<li>The bigger = the better on low-resource languages</li>
					<li>Wait, LLM as an embedding model?</li>
				</ul>
			</section>
			<section>
				<h2>Decoder-only embeddings</h2>
				<img src="img/decoder.png" height="400px" style="margin: 0px;">
				<ul>
					<li>BERT embeddings: bidirectional attention</li>
					<li>Decoder embeddings: only last token knows it all</li>
					<li>Decoders: prefill+generation stages</li>
				</ul>
			</section>
			<section>
				<img src="img/qwen3.png" height="550px">
			</section>
			<section>
				<h2>okey retrieval = quepid time?</h2>
				<ul>
					<li><strong>Perfect world</strong>: get queries, label results</li>
					<li><strong>Reality</strong>: "who's going to label results?"</li>
				</ul>
				<p>RAGAS approach: LLM-as-a-judge</p>
			</section>
			<section>
				<h2>Context precision+recall</h2>
				<img src="img/precision-recall.png" height="500px" style="margin: 0px;">
				<p>No NDCG: position does not matter for LLM</p>
			</section>
			<section>
				<h2>Context relevance</h2>
				<img src="img/precision-recall-emb.png" height="550px" style="margin: 0px;">
			</section>
			<section>
				<h2>Context retrieval metrics overview</h2>
				<ul>
					<li>Absolute numbers: not much benefit</li>
					<li>Relative performance: with automated evals!</li>
				</ul>
			</section>
			<section>
				<h2>G in RAG</h2>
				<img src="img/rag-nut.png" height="300px">
				<ul>
					<li>What open LLM to use?</li>
					<li>Balance: precision, hardware, latency</li>
				</ul>
			</section>
			<section>
				<h2>Evaluating generation</h2>
				<img src="img/rag-diag.png" height="450px" style="margin: 0px;">
				<ul>
					<li><strong>Comprehension</strong>: how LLM can understand language?</li>
					<li><strong>Generation</strong>: how good is generated response?</li>
				</ul>
			</section>
			<section>
				<h2>FB Belebele benchmark</h2>
				<img src="img/belebele.png" height="450px" style="margin: 0px;">
				<ul>
					<li>122 languages: passage, question, 4 answers</li>
					<li>400 triplets per language</li>
				</ul>
			</section>
			<section>
				<h2>Task example</h2>
				<pre><code>
Passage:
The atom can be considered to be one of the fundamental building blocks of 
all matter. Its a very complex entity which consists, according to a simplified 
Bohr model, of a central nucleus orbited by electrons, somewhat similar to 
planets orbiting the sun - see Figure 1.1. The nucleus consists of two 
particles - neutrons and protons. Protons have a positive electric charge 
while neutrons have no charge. The electrons have a negative electric charge.
	
Query: The particles that orbit the nucleus have which type of charge?
	
A: Positive charge
B: No charge
C: Negative charge
D: Positive and negative charge					
				</code></pre>
				<ul>
					<li>TLDR: NLU evaluation, but multilingual</li>
				</ul>
			</section>
			<section>
				<h2>Results</h2>
				<img src="img/belebele-results.jpg" style="margin: 0px;">
				<p>TLDR: Gemma2 (and 3!) is one of the best open LLMs</p>
			</section>
			<section>
				<h2>Benchmarking generation</h2>
				<img src="img/perplexity.webp">
				<p><small>[1]: <a
							href="https://blog.uptrain.ai/decoding-perplexity-and-its-significance-in-llms/">UpTrain:
							Decoding Perplexity and its significance in LLMs</a></small></p>
			</section>
			<section>
				<h2>Perplexity</h2>
				<img src="img/perp-results.jpg">
			</section>
			<section>
				<h2></h2>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			history: true,
			controls: true,
			progress: true,
			width: 1200,
			transition: 'none',
			slideNumber: true,
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
		});
	</script>
</body>

</html>